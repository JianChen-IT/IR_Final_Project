{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems\n",
    "\n",
    "Students: Irene Cantero (U151206) / Jian Chen (U150279)\n",
    "\n",
    "This notebook contains the 4 algorithms requested in the project sentence + 1 algorithm chose by us.\n",
    "\n",
    "Content:\n",
    "\n",
    "- Alternate Least Squares (ALS)\n",
    "- Adamic-Adar\n",
    "- Personalized PageRank\n",
    "- Node2Vec\n",
    "- Doc2Vec (chose by us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_engine.search_engine import SearchEngine\n",
    "import networkx as nx\n",
    "from networkx import Graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from fast_pagerank import pagerank\n",
    "from fast_pagerank import pagerank_power\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import igraph\n",
    "import warnings\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection time: 0.0\n"
     ]
    }
   ],
   "source": [
    "search_engine = SearchEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a graph where the vertices are formed by the users that retweet (users u) and the retweeted users (users v)\n",
    "#And the edge is the connection of users u to users v\n",
    "graph=igraph.Graph()\n",
    "for tweet in search_engine.tweets.iterrows():\n",
    "    if str(tweet[1]['retweeted_status'])!='nan':\n",
    "        u=tweet[1]['user']['screen_name']\n",
    "        v=tweet[1]['retweeted_status']['user']['screen_name']\n",
    "        graph.add_vertices(u)\n",
    "        graph.add_vertices(v)\n",
    "        graph.add_edges([(u,v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT USER:\n",
    "# If you change the user id, the recommendation of all 4 algorithms will try to satisfy that user.\n",
    "user_id=0\n",
    "user_name=graph.vs[user_id]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_at_distance_2(graph: igraph.Graph, test_idxs: list) -> set:\n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in graph.vs:\n",
    "        if n1.index in test_idxs:\n",
    "            # all the nodes at distance 1\n",
    "            nodes_at_most_distant_1 = set(graph.neighborhood(n1, order=1))\n",
    "            # all the nodes at distance 1 and distance 2\n",
    "            nodes_at_most_distant_2 = set(graph.neighborhood(n1, order=2))\n",
    "            # only the nodes at distance 2\n",
    "            only_nodes_at_distance_2 = nodes_at_most_distant_2 - nodes_at_most_distant_1\n",
    "\n",
    "            # check if empty set\n",
    "            if len(only_nodes_at_distance_2) > 0:\n",
    "                for n2 in only_nodes_at_distance_2:\n",
    "                    # since n1 is an igraph vertex object, we need to extract the id\n",
    "                    n1_index = n1.index\n",
    "                    all_potential_recommendations.add((n1_index, n2))\n",
    "            \n",
    "    return all_potential_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fraction of edges to select as test-set\n",
    "p = 0.2\n",
    "# graphsize\n",
    "N = len(graph.es)\n",
    "# idxs of all the edges\n",
    "all_idxs = range(N)\n",
    "# sample idxs of edges through the function \"choice\"\n",
    "test_idxs = np.random.choice(a=all_idxs, size=int(p*N),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "\n",
    "for idx, one_edge in enumerate(graph.es):\n",
    "    # take n1 and n2 idx from one_edge, that is an igraph edge *object*\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "    if idx in test_idxs:\n",
    "        ground_truth.add((n1, n2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_potential_recommendations = nodes_at_distance_2(graph, list(test_idxs))\n",
    "for rec in all_potential_recommendations:\n",
    "    # add to ground truth also the potential nodes\n",
    "    n1 = rec[0]\n",
    "    n2 = rec[1]\n",
    "    ground_truth.add((n1,n2,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS (Alternating Least Squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition that converts the users id to user names\n",
    "def number_to_username(alg_list: list, g) -> list:\n",
    "    alg_list_transformed=[]\n",
    "    for i in range(len(alg_list)):\n",
    "        name=g.vs[int(alg_list[i][0])]['name']\n",
    "        new_tuple=(name, alg_list[i][1])\n",
    "        alg_list_transformed.append(new_tuple)\n",
    "    return alg_list_transformed\n",
    "\n",
    "#It returns the user recommendations given a user_id\n",
    "def recommend_users(user_id: int, G:csr_matrix, g: igraph.Graph, top: int = 10) -> list:\n",
    "    ALS_recommended_users=model.recommend(user_id, G, top)\n",
    "    return ALS_recommended_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an adjency matrix from the graph\n",
    "G = graph.get_adjacency().data\n",
    "#Convert the adjency matrix to csr_matrix, which is the variable type needed for doing ALS \n",
    "G = csr_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be0e2b1b19445b6abb321655849b754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize ALS model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=10, iterations=5, calculate_training_loss=True)\n",
    "#Train ALS model\n",
    "model.fit(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendations for user Liensevi with id 0 using ALS (Alternate Least Squares):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LouDobbs', 1.27170915e-05),\n",
       " ('GenFlynn', 1.1479422e-05),\n",
       " ('drdavidsamadi', 7.779039e-06),\n",
       " ('KimM53904472', 3.3860933e-06),\n",
       " ('thewatchfulmom', 3.2320272e-06),\n",
       " ('aarfreethinker', 3.2208013e-06),\n",
       " ('michellemalkin', 3.0228725e-06),\n",
       " ('RyanAFournier', 2.9403664e-06),\n",
       " ('RebekahKirkla15', 2.8612235e-06),\n",
       " ('paulsperry_', 2.7980038e-06)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get user ids recommendations for a user\n",
    "ALS_recomdetaion_ids=recommend_users(user_id, G, graph)\n",
    "#Transform the user ids to their repective name\n",
    "ALS_recomdetaion_names=number_to_username(ALS_recomdetaion_ids, graph)\n",
    "print(f\"Recomendations for user {user_name} with id {user_id} using ALS (Alternate Least Squares):\")\n",
    "ALS_recomdetaion_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALS testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ALS(testset, model):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "    # scroll the obs\n",
    "    for n1,n2, _ in testset:\n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        array_n1 = model.user_factors[n1,:]\n",
    "        array_n2 = model.item_factors[n2,:]\n",
    "        # multiplying these vectors we generate an approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_test_als = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions = predict_ALS(df_test_als.values, model)\n",
    "# add predictions to df\n",
    "df_test_als[\"rating\"] = all_predictions\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "df_test_als[\"rating\"] = df_test_als[\"rating\"].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ALS: 0.9299307958477508\n"
     ]
    }
   ],
   "source": [
    "# number of observations matched by the prediction\n",
    "right_predictions_als = len(df_test_als[df_test_als.edge == df_test_als.rating])\n",
    "# accuracy\n",
    "print(f\"Accuracy for ALS: {right_predictions_als/len(df_test_als)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamic-Adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(user_a, g: igraph.Graph) -> list:\n",
    "    #We only need to consider those verices at distance 2\n",
    "    #We take those users at distance 1\n",
    "    neighbors_1=set(g.neighborhood(user_a, order=1))\n",
    "    #We take those users at distance 1 & 2\n",
    "    neighbors_2=set(g.neighborhood(user_a, order=2))\n",
    "    #We take only those nodes that are at distance 2\n",
    "    return list(neighbors_2 - neighbors_1)\n",
    "#Implementation of Adamic-Adar algorithm\n",
    "\n",
    "def get_recommendation_AA(username: int, g:igraph.Graph) -> pd.DataFrame:\n",
    "    neighbors_only_order_2=get_neighbors(username, g)\n",
    "    #Initialize dataframe with the user we want to recommend to as the column, and their 2-distance neighbors as indexes\n",
    "    adamic_adar_data=pd.DataFrame(columns=[username], index=neighbors_only_order_2)\n",
    "    #For every 2-distance users compute AA(x,y)\n",
    "    for user_y in neighbors_only_order_2:\n",
    "        if username!=user_y:\n",
    "            #Get neighbors for the two nodes\n",
    "            x_neighbors=set(g.neighborhood(username))\n",
    "            y_neighbors=set(g.neighborhood(user_y))\n",
    "        #Get only those nodes that are neighbors of both nodes\n",
    "        same_neighbors=x_neighbors&y_neighbors\n",
    "        aa_val=0\n",
    "        #Compute the Adamic-Avar value and add it to the dataframe\n",
    "        for n in same_neighbors:\n",
    "            num_neighbors=len(g.neighbors(n))\n",
    "            aa_val+=(1/math.log(num_neighbors,10))\n",
    "        adamic_adar_data[username][user_y]=aa_val\n",
    "    #Sort values and return the top 10 recommendations\n",
    "    top_n_recommendations_aa=adamic_adar_data[username].sort_values(ascending=False)\n",
    "    aa_final_recommendation=pd.DataFrame(top_n_recommendations_aa)\n",
    "    return aa_final_recommendation\n",
    "\n",
    "def pair_recommendation_AA(user_a: int, user_b: int, graph: igraph.Graph) -> int:\n",
    "    a_neighbors=set(graph.neighborhood(user_a))\n",
    "    b_neighbors=set(graph.neighborhood(user_b))\n",
    "    common_neighbors=a_neighbors&b_neighbors\n",
    "    aa_val=0\n",
    "    #Compute the Adamic-Avar value and return\n",
    "    for n in common_neighbors:\n",
    "        if user_a!=n:\n",
    "            num_neighbors=len(graph.neighbors(n))\n",
    "            aa_val+=(1/math.log(num_neighbors,10))\n",
    "    return aa_val\n",
    "\n",
    "#Transform user ids to user names\n",
    "def AA_num_to_name(dataset: pd.DataFrame, g: igraph.Graph)->pd.DataFrame:\n",
    "    old_indices=list(dataset.index)\n",
    "    new_indices=[]\n",
    "    main_user_id=dataset.columns[0]\n",
    "    main_user_name=g.vs[main_user_id]['name']\n",
    "    for user_id in old_indices:\n",
    "        name=g.vs[user_id]['name']\n",
    "        new_indices.append(name)\n",
    "    new_dataset=pd.DataFrame(dataset.values, columns=[main_user_name], index=new_indices)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendations for user Liensevi with id 0 using Adamic-Adar:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liensevi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N30Foll0w</th>\n",
       "      <td>1.43068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FloydStad</th>\n",
       "      <td>1.43068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kasmouse</th>\n",
       "      <td>1.43068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dennis91842840</th>\n",
       "      <td>1.43068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Liensevi\n",
       "N30Foll0w       1.43068\n",
       "FloydStad       1.43068\n",
       "kasmouse        1.43068\n",
       "dennis91842840  1.43068"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get recommended users ids for the requested user \n",
    "AA_recommendation_ids=get_recommendation_AA(user_id, graph)\n",
    "#Transform the ids to usernames\n",
    "AA_recommendation_names=AA_num_to_name(AA_recommendation_ids, graph)\n",
    "print(f\"Recomendations for user {user_name} with id {user_id} using Adamic-Adar:\")\n",
    "AA_recommendation_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamic Adar Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_AA(testset, graph):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "    # scroll the obs\n",
    "    for n1,n2, _ in testset:\n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        if n1!=n2:\n",
    "            try:\n",
    "                aa_score = pair_recommendation_AA(n1,n2, graph)\n",
    "            except:\n",
    "                aa_score=0\n",
    "        all_predictions.append(aa_score)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_test_aa = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions_aa = predict_AA(df_test_aa.values, graph)\n",
    "# add predictions to df\n",
    "df_test_aa[\"rating\"] = all_predictions_aa\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "df_test_aa[\"rating\"] = df_test_aa[\"rating\"].apply(lambda x: 1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Adamic-Adar: 0.8515354671280276\n"
     ]
    }
   ],
   "source": [
    "# number of observations matched by the prediction\n",
    "right_predictions_aa = len(df_test_aa[df_test_aa.edge == df_test_aa.rating])\n",
    "# accuracy\n",
    "print(f\"Accuracy for Adamic-Adar: {right_predictions_aa/len(df_test_aa)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform user ids to user names\n",
    "def pagerank_clearer(pagerank_values: list, g: igraph.Graph) -> list:\n",
    "    pagerank=[]\n",
    "    for i in range(len(pagerank_values)):\n",
    "            user=pagerank_values[i][0]\n",
    "            name=g.vs[user]['name']\n",
    "            val=float(pagerank_values[i][1])\n",
    "            pagerank.append((name, val))\n",
    "    return pagerank\n",
    "\n",
    "#From the score obtained from PageRank algorithm, get top user ids with higher score and that are 2-distance neighbors\n",
    "def top_10_ids(pagerank_result: list, user_id: int, graph: igraph.Graph)->list:\n",
    "    pagerank_with_ids=[]\n",
    "    \n",
    "    #We only need to consider those verices at distance 2\n",
    "    #We take those users at distance 1\n",
    "    neighbors_1=set(graph.neighborhood(user_id, order=1))\n",
    "    #We take those users at distance 1 & 2\n",
    "    neighbors_2=set(graph.neighborhood(user_id, order=2))\n",
    "    #We take only those nodes that are at distance 2\n",
    "    neighbors_only_order_2=list(neighbors_2 - neighbors_1)\n",
    "    \n",
    "    for i in range(len(pagerank_result)):\n",
    "        if i!=user_id and i in neighbors_only_order_2:\n",
    "            pagerank_with_ids.append([i, pagerank_result[i]])\n",
    "    pagerank_with_ids.sort(key = lambda x: x[1], reverse=True)\n",
    "    pagerank_top_10_ids=pagerank_with_ids[0:10]\n",
    "    return pagerank_top_10_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendations for user Liensevi with id 0 using Personalized PageRank:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kasmouse', 0.0807136386394075),\n",
       " ('dennis91842840', 0.06518142272913913),\n",
       " ('N30Foll0w', 0.06518142272913913),\n",
       " ('FloydStad', 0.06518142272913913)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get PageRank scores for each user given the initial node/user\n",
    "PageRank_recommendations=graph.personalized_pagerank(reset_vertices=user_id)\n",
    "#Get top users ids with higher score and that are 2-distance neighbor \n",
    "PageRank_recommendation_ids=top_10_ids(PageRank_recommendations, user_id, graph)\n",
    "#Transform the ids to usernames\n",
    "PageRank_recommendation_names=pagerank_clearer(PageRank_recommendation_ids, graph)\n",
    "print(f\"Recomendations for user {user_name} with id {user_id} using Personalized PageRank:\")\n",
    "PageRank_recommendation_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Pagerank testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pr(testset, graph):\n",
    "    all_predictions = []\n",
    "    for n1, n2, _ in testset:\n",
    "        ranking = graph.personalized_pagerank(vertices=n2, reset_vertices = n1)\n",
    "        all_predictions.append(ranking)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_test_pr = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions_pr = predict_pr(df_test_pr.values,graph)\n",
    "# add predictions to df\n",
    "df_test_pr[\"rating\"] = all_predictions_pr\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "df_test_pr[\"rating\"] = df_test_pr[\"rating\"].apply(lambda x: 1 if x > 0.05 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Personalized Pagerank: 0.9359320934256056\n"
     ]
    }
   ],
   "source": [
    "# number of observations matched by the prediction\n",
    "right_predictions_pr = len(df_test_pr[df_test_pr.edge == df_test_pr.rating])\n",
    "# accuracy\n",
    "print(f\"Accuracy for Personalized Pagerank: {right_predictions_pr/len(df_test_pr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to apply Node2vec, we need to convert the igraph to a networkx graph\n",
    "A = graph.get_edgelist()\n",
    "nx_graph = nx.Graph(A) # In case your graph is directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491e04d98a6b47359e8b98b10287539e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing transition probabilities', max=7377.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize Node2vec model\n",
    "n2v = node2vec.Node2Vec(nx_graph, dimensions=64, walk_length=2, num_walks=200, workers=4) \n",
    "#Train Node2vec model\n",
    "model = n2v.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of the recommended users with their respective scores of the initial/main node\n",
    "user_id_str=str(user_id)\n",
    "node2vec_recommendation_ids=model.wv.most_similar(user_id_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1286', 0.9995108246803284),\n",
       " ('3246', 0.9993603229522705),\n",
       " ('272', 0.9992141723632812),\n",
       " ('3666', 0.9215577840805054),\n",
       " ('2878', 0.7088077664375305),\n",
       " ('9946', 0.7081505060195923),\n",
       " ('11764', 0.7076790928840637),\n",
       " ('9936', 0.7061811685562134),\n",
       " ('1800', 0.7060530781745911),\n",
       " ('13430', 0.7050497531890869)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2vec_recommendation_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Transform user ids to user names\n",
    "node2vec_recommendation_names=number_to_username(node2vec_recommendation_ids, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendations for user Liensevi with id 0 using Node2vec:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('FloydStad', 0.9991071224212646),\n",
       " ('N30Foll0w', 0.9989970922470093),\n",
       " ('dennis91842840', 0.9987884759902954),\n",
       " ('kasmouse', 0.9028507471084595),\n",
       " ('Nic04588534', 0.6528711318969727),\n",
       " ('IvonneMeeuwsen', 0.651504635810852),\n",
       " ('RussLSmith', 0.6512831449508667),\n",
       " ('margie_wateland', 0.6504145860671997),\n",
       " ('DocLionel1', 0.6494978666305542),\n",
       " ('JimWatkins', 0.648861825466156)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Recomendations for user {user_name} with id {user_id} using Node2vec:\")\n",
    "node2vec_recommendation_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nv(testset, model):\n",
    "    all_predictions = []\n",
    "    for n1, n2, _ in testset:\n",
    "        ranking = model.wv.similarity(str(n1), str(n2))\n",
    "        all_predictions.append(ranking)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_test_nv = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions_nv = predict_nv(df_test_nv.values, model)\n",
    "# add predictions to df\n",
    "df_test_nv[\"rating\"] = all_predictions_nv\n",
    "# convert predictions to binary values: 0 don't add the edge, 1 add it.\n",
    "df_test_nv[\"rating\"] = df_test_nv[\"rating\"].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Node2Vec: 0.027411332179930796\n"
     ]
    }
   ],
   "source": [
    "# number of observations matched by the prediction\n",
    "right_predictions_nv = len(df_test_nv[df_test_nv.edge == df_test_nv.rating])\n",
    "# accuracy\n",
    "print(f\"Accuracy for Node2Vec: {right_predictions_nv/len(df_test_nv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + Cosine Similarity Recommender System\n",
    "\n",
    "As we have seen in the theories, TF-IDF + Cosine Similarity or Pearson Coefficient can also recommend potential items to a given user. In this case, we did something similar, but this time, given a tweet it recommends other tweets. The thing to demonstrate here is that a recommender system is almost the same as a search engine, but now the \"query\" is the user profile, or in our case a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_custom_score(user: str, tweets: pd.DataFrame):\n",
    "    user_sample_tweet=''\n",
    "    # Relevant document scoring\n",
    "    for i in range(len(tweets)):\n",
    "        if tweets['user'][i]['screen_name'] == user:\n",
    "            user_sample_tweet = tweets['text'][i]\n",
    "            break\n",
    "    if user_sample_tweet == '':\n",
    "        return\n",
    "    tweets_score = search_engine.ranking_system_ex_3.cosine_similarity(\n",
    "        user_sample_tweet, list(tweets.index)\n",
    "    )\n",
    "    results = pd.DataFrame(columns = [\"User\", \"Similarity\"])\n",
    "    # Score assignation\n",
    "    recommended_tweets = []\n",
    "    cosine_similarities = []\n",
    "    for i in range(len(tweets)):\n",
    "        recommended_tweets.append(tweets[\"user\"][i]['screen_name'])\n",
    "        cosine_similarities.append(tweets_score[i])\n",
    "\n",
    "    results[\"Similarity\"] = cosine_similarities\n",
    "    results[\"User\"] = recommended_tweets\n",
    "\n",
    "    # Sort by descending score\n",
    "    results_sorted = results.sort_values(\n",
    "        by=[\"Similarity\"], ascending=False\n",
    "    )\n",
    "\n",
    "    return results_sorted.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf_idf_custom_score(user_name, search_engine.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liensevi</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N30Foll0w</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FloydStad</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lah3309</td>\n",
       "      <td>0.235331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LivingOhioDream</td>\n",
       "      <td>0.217845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ace77ofnocal</td>\n",
       "      <td>0.214249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DebraH74710152</td>\n",
       "      <td>0.176193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cockyman7</td>\n",
       "      <td>0.176193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stofer99</td>\n",
       "      <td>0.176193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jcounselman3</td>\n",
       "      <td>0.176193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User  Similarity\n",
       "0         Liensevi    1.000000\n",
       "1        N30Foll0w    1.000000\n",
       "2        FloydStad    1.000000\n",
       "3          lah3309    0.235331\n",
       "4  LivingOhioDream    0.217845\n",
       "5     Ace77ofnocal    0.214249\n",
       "6   DebraH74710152    0.176193\n",
       "7        cockyman7    0.176193\n",
       "8         stofer99    0.176193\n",
       "9     jcounselman3    0.176193"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
