{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler, Stream, API, Cursor\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## access token informations \n",
    "access_token1 = \"1222829174802538496-AXkAccE1dWMjuEFlEYChpgOibc6SbF\"\n",
    "access_token_secret1 = \"jtr66CvVvspsANplSBpuMEQR5iLwK2fRtzM6aDhaC1rZT\"\n",
    "\n",
    "consumer_key1 = \"sL9E5QL83DVEshfttLjEEj930\"\n",
    "consumer_secret1 = \"R9L4Ar7UWTKB4WQw7cEoybumyTInZ6pYP3cQ5GFlWYFllYAeec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key1, consumer_secret1)\n",
    "auth.set_access_token(access_token1, access_token_secret1)\n",
    "api = API(auth_handler=auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(StreamListener):\n",
    "    \"\"\"\n",
    "    Twitter listener, collects streaming tweets and output to a file\n",
    "    \"\"\"\n",
    "    def __init__(self, api, OUTPUT_FILENAME, stop_condition=10):\n",
    "        \"\"\"\n",
    "        initialize the stream, with num. of tweets and saving the outputfile\n",
    "        \"\"\"\n",
    "        \n",
    "        # this line is needed to import the characteristics of the streaming API\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        \n",
    "        # to-count the number of tweets collected        \n",
    "        self.num_tweets = 0\n",
    "        \n",
    "        # save filename\n",
    "        self.filename = OUTPUT_FILENAME\n",
    "        \n",
    "        # stop-condition\n",
    "        self.stop_condition = stop_condition\n",
    "        \n",
    "\n",
    "    def on_status(self, status):\n",
    "        \n",
    "        \"\"\"\n",
    "        this function runs each time a new bunch of tweets is retrived from the streaming\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(self.filename, \"a+\") as f:\n",
    "            tweet = status._json\n",
    "            \n",
    "            f.write(json.dumps(tweet) + '\\n')\n",
    "            #self.output.append(tweet)\n",
    "            self.num_tweets += 1\n",
    "        \n",
    "            # Stop condition        \n",
    "            if self.num_tweets <= self.stop_condition:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "\n",
    "    def on_error(self, status):\n",
    "        \"\"\"\n",
    "        function useful to handle errors. It's possible to personalize it \n",
    "        depending on the way we want to handle errors\n",
    "        \"\"\"\n",
    "        \n",
    "        print(status)\n",
    "        #returning False in on_error disconnects the stream\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = \"other-outputs/tweets_US_Election_2020.json\"\n",
    "stop_condition = 500\n",
    "\n",
    "l = MyStreamListener(api, OUTPUT_FILENAME, stop_condition)\n",
    "# here we recall the Stream Class from Tweepy to input the authentication info and our personalized listener \n",
    "stream = Stream(auth=api.auth, listener=l)\n",
    "\n",
    "\n",
    "# keywords we may want decide to track \n",
    "TRACKING_KEYWORDS = [\"Donald\", \"Trump\", \"Joe\", \"Biden\", \"America\", \"USA\"]\n",
    "stream.filter(\n",
    "    track=TRACKING_KEYWORDS, \n",
    "    is_async=False, \n",
    "    languages = [\"en\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_Election_file = []\n",
    "for line in open(OUTPUT_FILENAME, 'r'):\n",
    "    json_Election_file.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train={}\n",
    "i=0\n",
    "for train_file in json_Election_file:\n",
    "    dict_train[i]=train_file\n",
    "    i+=1\n",
    "train = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "train.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @iamjumpingin: 1st they choose Biden to be ...\n",
       "1    RT @LLinWood: The Georgia Governor &amp; Secre...\n",
       "2    RT @Forecast432hz: NO SHIT ðŸ‘‡ðŸ¼\\nFacebook, Twitt...\n",
       "3    @violethaze10 @rhonda0228 @NewDayForNJ Yeah I ...\n",
       "4    RT @MoralScold: @RealMattCouch God, please giv...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize functions:\n",
    "def stemming(text: str) -> None:\n",
    "    pass\n",
    "def punctuation_removal(text: str) -> None:\n",
    "    pass\n",
    "def remove_stop_words(text: str) -> None:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
