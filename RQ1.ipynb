{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine\n",
    "\n",
    "Students: Irene Cantero (U151206) / Jian Chen (U150279)\n",
    "\n",
    "All the code is stored in the folder `search_engine`. The notebook only contains the calls and some functions to do the T-SNE and the clustering.\n",
    "\n",
    "Content: \n",
    "\n",
    "- Top 10 results only using TF-IDF + Cosine similarity for 10 chosen queries\n",
    "- Top 10 results using Word2Vec + Cosine similarity for the same 10 chosen queries\n",
    "- Search with custom score G(d) + cosine similarity for a given query\n",
    "        - G(d) considers the (1/2)Tweets likes, (1/3)retweets and (1/6) replies\n",
    "- T-SNE implementation and plot using T-SNE.\n",
    "- Plot to see the optimal number of clusterings.\n",
    "- Clustering using K means and the optimal number of clusterings, showing the most common words of each cluster as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_engine.search_engine import SearchEngine\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection time: 0.0\n"
     ]
    }
   ],
   "source": [
    "search_engine = SearchEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the search engine considering the popularity (Likes, Retweets and Replies) of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "search_engine.ranking_system.change_user_input(1)\n",
    "#print(\"Insert your query:\\n\")\n",
    "query = \"joe biden\"\n",
    "\n",
    "search_engine.run(query).query(\"score > 0\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "search_engine.ranking_system.change_user_input(1)\n",
    "#print(\"Insert your query:\\n\")\n",
    "query = \"joe biden\"\n",
    "search_engine.run_g(query).query(\"score > 0\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to answer RQ1b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "#chosen queries\n",
    "queries=[]\n",
    "queries.append(\"joe biden won elections\")\n",
    "queries.append(\"donald trump is the president\")\n",
    "queries.append(\"elections are a fraud\")\n",
    "queries.append(\"pennsylvania\")\n",
    "queries.append(\"trump out\")\n",
    "queries.append(\"votes fraud\")\n",
    "queries.append(\"i voted\")\n",
    "queries.append(\"georgia votes\")\n",
    "queries.append(\"trump team\")\n",
    "queries.append(\"biden team\")\n",
    "\n",
    "#NOTE: to open the tsv correctly use UTF-8\n",
    "try:\n",
    "    os.remove('other-outputs/RQ1b.tsv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "search_engine.ranking_system.change_user_input(1) #Using TF-IDF + cosine_similarity\n",
    "# Setting the header of the TSV file\n",
    "RQ1 = open('other-outputs/RQ1b.tsv', 'a+')\n",
    "RQ1.write(\"\\tTweet\\tUsername\\tDate\\tHashtags\\tLikes\\tRetweets\\tReplies\\tUrl\\tScore\\n\")\n",
    "RQ1.close()\n",
    "\n",
    "# Storing each result of each query in the TSV file\n",
    "for query in queries:\n",
    "    RQ1 = open('other-outputs/RQ1b.tsv', 'a+')\n",
    "    RQ1.write(f\"QUERY\\t{query}\\n\")\n",
    "    RQ1.close()\n",
    "    print(f\"\\nQUERY: {query.upper()}\\n\")\n",
    "    results=search_engine.run(query).query(\"score > 0\").head(20)\n",
    "    display(results)\n",
    "    results.replace('\\n',' ', regex=True).to_csv(path_or_buf='other-outputs/RQ1b.tsv', sep='\\t', header=False, mode = 'a')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to the answer RQ1c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.ranking_system.change_user_input(2) #Using Word2Vec + cosine_similarity\n",
    "#chosen queries\n",
    "queries=[]\n",
    "queries.append(\"joe biden won elections\")\n",
    "queries.append(\"donald trump is the president\")\n",
    "queries.append(\"elections are a fraud\")\n",
    "queries.append(\"pennsylvania\")\n",
    "queries.append(\"trump out\")#3\n",
    "queries.append(\"votes fraud\")\n",
    "queries.append(\"i voted\")\n",
    "queries.append(\"georgia votes\")\n",
    "queries.append(\"trump team\")\n",
    "queries.append(\"biden team\")\n",
    "\n",
    "#NOTE: to open the tsv correctly use UTF-8\n",
    "try:\n",
    "    os.remove('other-outputs/RQ1c.tsv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Setting the header of the TSV file\n",
    "RQ1 = open('other-outputs/RQ1c.tsv', 'a+')\n",
    "RQ1.write(\"\\tTweet\\tUsername\\tDate\\tHashtags\\tLikes\\tRetweets\\tReplies\\tUrl\\tScore\\n\")\n",
    "RQ1.close()\n",
    "\n",
    "# Storing each result of each query in the TSV file\n",
    "for query in queries:\n",
    "    RQ1 = open('other-outputs/RQ1c.tsv', 'a+')\n",
    "    RQ1.write(f\"QUERY\\t{query}\\n\")\n",
    "    RQ1.close()\n",
    "    print(f\"\\nQUERY: {query.upper()}\\n\")\n",
    "    results=search_engine.run(query).query(\"score > 0\").head(20)\n",
    "    display(results)\n",
    "    results.replace('\\n',' ', regex=True).to_csv(path_or_buf='other-outputs/RQ1c.tsv', sep='\\t', header=False, mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can you imagine a better representation than word2vec? Justify your answer.\n",
    "#(HINT - what about Doc2vec? Sentence2vec? Which are the pros and cons?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs K-means to see what are the best number of clusters, recollects the words of each cluster\n",
    "# of tweets and gives labels\n",
    "def KMeans_setup(model) -> None:\n",
    "    total_tokens=[]\n",
    "    tweets_words = []\n",
    "    # for to do word embedding using word2vec and collecting words from the tweets\n",
    "    for tweet in search_engine.tweets[\"text\"]:\n",
    "        tweet_words = {}\n",
    "        tokens = []\n",
    "        # for each word of the tweet do word emebeding, and add it to the dictionary of the tweet. If \n",
    "        # it exists already, then just add 1\n",
    "        for word in tweet.split():\n",
    "            try:\n",
    "                tokens.append(model[word])\n",
    "                if word not in tweet_words.keys():\n",
    "                    tweet_words[word] = 1\n",
    "                else:\n",
    "                    tweet_words[word]+=1\n",
    "            except:\n",
    "                pass\n",
    "        # We do the mean of the word embeddings to represent the tweet (Tweet2Vec)\n",
    "        tokens = np.mean(np.array(tokens), axis=0)\n",
    "        # For the tweets, we just append it to the tweets_words. Since the embedded tweet and tweet words are in the same order,\n",
    "        # we do not need any mapping function to make sure that the tweet words corresponds to the embedded tweet.\n",
    "        tweets_words.append(tweet_words)\n",
    "        if str(tokens) != 'nan':\n",
    "            total_tokens.append(tokens)\n",
    "    \n",
    "    # Plot the sum of square distance depending on the number of clusterings\n",
    "    K = range(1,15)\n",
    "    Sum_of_squared_distances = []\n",
    "    for k in K:\n",
    "        km = KMeans(n_clusters=k)\n",
    "        km = km.fit(total_tokens)\n",
    "        Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "    plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum_of_squared_distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "    return total_tokens, tweets_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function of the T-SNE plot, which takes as inputs the output of the function Kmeans_Setup\n",
    "# The number of clusters have been set according to the plot of Kmeans_setup.\n",
    "def tsne_plot(total_tokens, tweet_words):\n",
    "    NUM_CLUSTERS = 3\n",
    "    # T-SNE setup\n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=5000, random_state=0)\n",
    "    new_values = tsne_model.fit_transform(total_tokens)\n",
    "    \n",
    "    # K-means setup with the specified number of clusters\n",
    "    kmeans = KMeans(n_clusters=NUM_CLUSTERS)\n",
    "    kmeans = kmeans.fit(total_tokens)\n",
    "    # getting the labels to do the coloring of each node (tweet.)\n",
    "    labels = kmeans.predict(total_tokens)\n",
    "    ColorsA=plt.cm.viridis(np.linspace(0, 1, NUM_CLUSTERS),alpha=0.8)\n",
    "    \n",
    "    # Getting the results of the T-SNE model by getting the coordinates of x,y of each tweet\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    clusters_common_words = []\n",
    "    \n",
    "    # Coloring each tweet node depending on the cluster it belongs. We take profit of the variable \"labels\" to do that\n",
    "    plt.figure(figsize=(10,10))\n",
    "    # For each cluster...\n",
    "    for i in range(NUM_CLUSTERS):\n",
    "        xL=[]\n",
    "        yL=[]\n",
    "        cluster_words = {}\n",
    "        # ... and for every tweet...\n",
    "        for k in range(len(x)):\n",
    "            # ...if the tweet belongs to the cluster get the coordinates, and store the words in a dictionary\n",
    "            if labels[k]==i:\n",
    "                xL.append(x[k])\n",
    "                yL.append(y[k])\n",
    "                # collecting and counting the number of words \n",
    "                for word in tweets_words[k]:\n",
    "                    if word not in cluster_words.keys():\n",
    "                        cluster_words[word] = 1\n",
    "                    else:\n",
    "                        cluster_words[word] += tweets_words[k].get(word)\n",
    "        # Associate all the words collected to a cluster\n",
    "        clusters_common_words.append(cluster_words)\n",
    "        plt.scatter(xL,yL,color=ColorsA[i])\n",
    "    \n",
    "    # Extra for loop just to show most common words of each cluster\n",
    "    for i in range(NUM_CLUSTERS):\n",
    "        print(dict(sorted(clusters_common_words[i].items(), key=lambda x: x[1], reverse=True)[:5]))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot show us the optimal number of clusters needed in our dataset. However, in this case is not very clear, because the \"elbow\" is not very well defined. We think that this is because the tweets are very similar between each other, and that leads us to have at most 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = search_engine.ranking_system.w2v\n",
    "total_tokens, tweets_words = KMeans_setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(total_tokens, tweets_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "tweets = search_engine.tweets\n",
    "words = \"\"\n",
    "for tweet in range(len(tweets)):\n",
    "        words +=tweets[\"text\"][tweet] + \" \"\n",
    "    \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='black', \n",
    "                min_font_size = 10).generate(words)\n",
    "\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}\n",
    "\n",
    "for tweet in range(len(tweets)):\n",
    "    for word in tweets[\"text\"][tweet].split():\n",
    "        if word not in tf.keys():\n",
    "            tf[word] = 1\n",
    "        else:\n",
    "            tf[word]+=1\n",
    "tf = dict(sorted(tf.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(list(tf.keys())[:5], height=list(tf.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(search_engine.original_tweets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
