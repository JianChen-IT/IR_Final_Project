{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_engine.search_engine import SearchEngine\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Insert your query:\\n\")\n",
    "query = input()\n",
    "search_engine.run(query).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"Insert your query:\\n\")\n",
    "query = input()\n",
    "search_engine.run(query).query(\"score > 0\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query:\n",
      "\n",
      "joe biden\n",
      "max score: 185848.83333333334\n",
      "min score: 0.5\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"Insert your query:\\n\")\n",
    "query = input()\n",
    "search_engine = SearchEngine()\n",
    "test=search_engine.run_g(query).query(\"total_score > 0\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test to get out rt:\n",
    "#print(text_normalization('RT, Toca.Ovaris, 20.000 or 20,00'))\n",
    "search_engine = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search(\"joe biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler, Stream, API, Cursor\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## access token informations \n",
    "access_token1 = \"1222829174802538496-AXkAccE1dWMjuEFlEYChpgOibc6SbF\"\n",
    "access_token_secret1 = \"jtr66CvVvspsANplSBpuMEQR5iLwK2fRtzM6aDhaC1rZT\"\n",
    "\n",
    "consumer_key1 = \"sL9E5QL83DVEshfttLjEEj930\"\n",
    "consumer_secret1 = \"R9L4Ar7UWTKB4WQw7cEoybumyTInZ6pYP3cQ5GFlWYFllYAeec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key1, consumer_secret1)\n",
    "auth.set_access_token(access_token1, access_token_secret1)\n",
    "api = API(auth_handler=auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = api.get_status(\"1333867678021410823\")\n",
    "tweet_retweets= api.retweets(\"1333867678021410823\")\n",
    "tweet_retweets[1]._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_retweets[1]._json[\"retweeted_status\"][\"reply_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyStreamListener(StreamListener):\n",
    "    \"\"\"\n",
    "    Twitter listener, collects streaming tweets and output to a file\n",
    "    \"\"\"\n",
    "    def __init__(self, api, OUTPUT_FILENAME, stop_condition=10):\n",
    "        \"\"\"\n",
    "        initialize the stream, with num. of tweets and saving the outputfile\n",
    "        \"\"\"\n",
    "        \n",
    "        # this line is needed to import the characteristics of the streaming API\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        \n",
    "        # to-count the number of tweets collected        \n",
    "        self.num_tweets = 0\n",
    "        \n",
    "        # save filename\n",
    "        self.filename = OUTPUT_FILENAME\n",
    "        \n",
    "        # stop-condition\n",
    "        self.stop_condition = stop_condition\n",
    "        \n",
    "\n",
    "    def on_status(self, status):\n",
    "        \n",
    "        \"\"\"\n",
    "        this function runs each time a new bunch of tweets is retrived from the streaming\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(self.filename, \"a+\") as f:\n",
    "            tweet = status._json\n",
    "            \n",
    "            f.write(json.dumps(tweet) + '\\n')\n",
    "            #self.output.append(tweet)\n",
    "            self.num_tweets += 1\n",
    "        \n",
    "            # Stop condition        \n",
    "            if self.num_tweets <= self.stop_condition:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "\n",
    "    def on_error(self, status):\n",
    "        \"\"\"\n",
    "        function useful to handle errors. It's possible to personalize it \n",
    "        depending on the way we want to handle errors\n",
    "        \"\"\"\n",
    "        \n",
    "        print(status)\n",
    "        #returning False in on_error disconnects the stream\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = \"other-outputs/tweets_US_Election_2021.json\"\n",
    "stop_condition = 100\n",
    "\n",
    "l = MyStreamListener(api, OUTPUT_FILENAME, stop_condition)\n",
    "# here we recall the Stream Class from Tweepy to input the authentication info and our personalized listener \n",
    "stream = Stream(auth=api.auth, listener=l)\n",
    "\n",
    "\n",
    "# keywords we may want decide to track \n",
    "TRACKING_KEYWORDS = [\"Donald\", \"Trump\", \"Joe\", \"Biden\", \"America\", \"USA\"]\n",
    "stream.filter(\n",
    "    track=TRACKING_KEYWORDS, \n",
    "    is_async=False, \n",
    "    languages = [\"en\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_Election_file = []\n",
    "for line in open(OUTPUT_FILENAME, 'r'):\n",
    "    json_Election_file.append(json.loads(line))\n",
    "\n",
    "    \n",
    "dict_train={}\n",
    "i=0\n",
    "for train_file in json_Election_file:\n",
    "    dict_train[i]=train_file\n",
    "    i+=1\n",
    "train = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "train.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
